<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AI Workflows for FOLIO - Prompt Engineering</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <style>

    </style>
  </head>
  <body>
    <div class="header">
     <div class="container">
       <h1 style="color: #0a3a85; font-size: 3em;">WOLFcon 2024 - Understanding and Using AI Workflows with FOLIO</h1>
       <h3>23 September 2024</h3>
       <hr>
     </div>
    </div>
    <div class="container">
    
      <div class="row">
        <article class="col-9">
         <h1>Prompt Engineering</h1>
<figure>
  <blockquote class="blockquote">
   The technique of prompt engineering, which entails the crafting of precise, 
   task-specific instructions in natural language, either manually or through 
   automated means, and the careful selection of representative examples for 
   inclusion in the prompt, has become a central area of investigation for LLMs.
  </blockquote>
  <figcaption class="blockquote-footer">
   Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4
   <sup id="fnref:PRINCIPLED"><a class="footnote-ref" href="#fn:PRINCIPLED">1</a></sup>
  </figcaption>
</figure>

<p>To effectively use Large Language Models (LLMs) and generative AI, you will need to construct a short textual 
description, called a prompt, that the LLM will use to generate text, images, or 
other media. Usually, you will need to iterate and change your prompt to improve the LLMs
outputs a few times until you have a result that meets your needs. </p>
<p>How you construct your prompt will also impact aspects of the model's output, like 
accuracy and verbosity or if you want to customize the style of the output. Together,
a set of techniques and approaches for constructing prompts is collective called 
prompt engineering. </p>
<p>In Anthropic's Prompt Engineering Guide, they suggest the before you begin applying 
specific prompt engineering techniques, you have a clear definition of success criteria
for your use case, ways to empirically test those criteria, and a first draft of your 
prompt.<sup id="fnref:ANTHROPIC"><a class="footnote-ref" href="#fn:ANTHROPIC">2</a></sup></p>
<h2>Popular Prompt Engineering Techniques</h2>
<h3>Zero Shot</h3>
<p>In a zero-shot prompt, ask the LLM perform a task that the LLM has not been explicitly 
trained on but is dependent on the LLM general knowledge and understanding of the language
based on it's training data. </p>
<p><strong>Example</strong>: Please translate this sentence into Spanish, "The 2024 Summer Olympics are being
held in France".</p>
<p>The LLM likely hasn't been trained on translating this exact sentence but uses it's general 
understanding and translation patterns to provide a response.  </p>
<h3>Including Examples or Multishot Prompting</h3>
<p>In this technique, you provide a few (1-5) examples of the LLMs output in your prompt and is 
particularly helpful when you require the output to include structured data like FOLIO JSON 
documents. </p>
<p><strong>Example</strong>: You are an expert cataloger, please return any records as FOLIO JSON, here is an
example:</p>
<pre><code>Q: Parable of the Sower by Octiva Butler, published in 1993 by Four Walls Eight Windows in New York 

A: {&quot;title&quot;: &quot;Parable of the Sower&quot;, &quot;source&quot;: &quot;ChatGPT&quot;, 
    &quot;contributors&quot;: [{&quot;name&quot;: &quot;Octiva Butler&quot;, &quot;contributorTypeText&quot;: &quot;Author&quot;}], 
    &quot;publication&quot;: [{&quot;publisher&quot;: &quot;Four Walls Eight Windows&quot;, &quot;dateOfPublication&quot;: &quot;1993&quot;, &quot;place&quot;: &quot;New York&quot;}] }}
</code></pre>
<h3>Chain-of-Thought</h3>
<p>Another useful prompt technique is called <em>chain-of-thought</em> where you explicitly ask 
the LLM to provide the reasoning or steps the model went through to construct the output.
This can be helpful if you're confused how or why a model return the output to your prompt.</p>
<p><strong>Example</strong> Create a circulation report template that includes all books that have been checked
out in the past month. Please show your thinking step-by-step as you construct the report.</p>
<h2>Remember you can combine multiple prompt techniques!</h2>
<p>For more examples, please check-out Prompt Engineering Guide<sup id="fnref:PROMPT_GUIDE"><a class="footnote-ref" href="#fn:PROMPT_GUIDE">3</a></sup>.</p>
<h2>Workshop Use-cases</h2>
<h3>Primary</h3>
<h3>Secondary</h3>
<h3>Tertiary</h3>
<div class="footnote">
<hr />
<ol>
<li id="fn:PRINCPLED">
<p><a href="https://arxiv.org/abs/2312.16171">Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</a>&#160;<a class="footnote-backref" href="#fnref:PRINCPLED" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:ANTHROPIC">
<p><a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/">Antropic Prompt Engineering Guide</a>&#160;<a class="footnote-backref" href="#fnref:ANTHROPIC" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:PROMPT_GUIDE">
<p><a href="https://www.promptingguide.ai/">Prompt Engineering Guide</a>&#160;<a class="footnote-backref" href="#fnref:PROMPT_GUIDE" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>
        </article>
        <div class="col-3">
          <h4>Navigation</h4>
          <ol><li><a href="/intro-pre-conference/index.html">Introduction to WOLFcon AI Pre-conference Workshop</a></li><li><a href="/types-of-ai-ml-relevant-to-libraries/index.html">General Overview of AI and Machine Learning for Libraries</a></li><li><a href="/ethical-considerations-ai-ml-for-libraries/index.html">Ethical Considerations on using AI and Machine Learning for Libraries</a></li><li><a href="/exploring-llms/index.html">Exploring Large Language Models</a><ul><li><a href="chatgpt.html">OpenAI's ChatGPT</a></li><li><a href="claude.html">Anthropic's Claude</a></li><li><a href="gemini.html">Google Gemini</a></li><li><a href="local-llama.html">Meta's Llama</a></li><li><a href="generative-video.html">Generative Image and Video</a></li><li><strong>Prompt Engineering</strong></li><li><a href="retrieval-augmented-generation.html">Retrieval Augmented Generation (RAG)</a></li><li><a href="training-llms.html">Training Large Language Models (LLMs)</a></li></ul></li><li><a href="/folio-ai-use-cases/index.html">FOLIO AI Use Cases</a></li><li><a href="/next-steps-for-adopting-ai-and-ml-in-folio/index.html">Next Steps for Adopting AI and Machine Learning in FOLIO</a></li><li><a href="/recommended-resources-for-further-learning/index.html">Recommended Resources for Further Learning</a></li></ol>
        </div>
      </div>

    </div>
    <footer style="background-color: #0a3a85; color: white;" >
      <div class="container">Original Content by Jeremy Nelson &copy; 2024, <a href="https://github.com/jermnelson/wolfcon-02024-ai">Github</a></div>
    </footer> 
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
  </body>
</html>