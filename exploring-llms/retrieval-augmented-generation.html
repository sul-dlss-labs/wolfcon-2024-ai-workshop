<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AI Workflows for FOLIO - Retrieval Augmented Generation (RAG)</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <style>

    </style>
  </head>
  <body>
    <div class="header">
     <div class="container">
       <h1 style="color: #0a3a85; font-size: 3em;">WOLFcon 2024 - Understanding and Using AI Workflows with FOLIO</h1>
       <h3>23 September 2024</h3>
       <hr>
     </div>
    </div>
    <div class="container">
    
      <div class="row">
        <article class="col-9">
         <h1>Retrieval Augmented Generation (RAG)</h1>
<p>Retrieval Augmented Generation (RAG) is a Natural Language Processing (NLP) 
technique to enhance and localize the use of generative based Large Language 
Models (LLMs) by including specific external content in the LLM's context window. </p>
<p>RAG is often employed to improve the accuracy and reliability of LLMs by 
better contextualizing the generative abilities of these models.</p>
<h3>Key features of RAG:</h3>
<ul>
<li>First proposed in a 2020 paper<sup id="fnref:RAG_NLP"><a class="footnote-ref" href="#fn:RAG_NLP">1</a></sup></li>
<li>Provides a means to ground LLM output</li>
<li>Allows LLMs to act as a narrative interface for document corpora or data repositories</li>
<li>Enables LLMs to cite specific documents or data, reducing the chance of incorrect answers</li>
</ul>
<h2>Embeddings and Vector Databases</h2>
<p>While the RAG technique doesn't require the use of embeddings or vector databases,
adding an information retrieval component to your RAG system can improve overall
performance of compound AI systems. To create a vector database, first the documents
or data is converted into a mathematical representation of meaning, a text embedding,
that is a set of numeric vectors that are used for matching and creating relationships.</p>
<p>These text embeddings are then stored in a database or datastore and then can be queried
by first converting a query into a text embedding and then finding the stored embeddings
that most closely match the query. The resulting embeddings are then converted back to
textual documents and then sent as a part of the context window to the LLM.</p>
<h2>Application to FOLIO</h2>
<p>Creating a vector database of FOLIO JSON documents offers a number of advantages to 
AI workflows; both in the generative aspects of creating new documents
like invoices or inventory records from text or automatic prompts, and
minimize errors in the LLMs output. </p>
<h2>Workshop Use-cases</h2>
<h3>Primary</h3>
<h3>Secondary</h3>
<h3>Tertiary</h3>
<div class="footnote">
<hr />
<ol>
<li id="fn:RAG_NLP">
<p><a href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a>&#160;<a class="footnote-backref" href="#fnref:RAG_NLP" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:GUIDE_RAG">
<p><a href="https://www.smashingmagazine.com/2024/01/guide-retrieval-augmented-generation-language-models/">A Simple Guide To Retrieval Augmented Generation Language Models</a>&#160;<a class="footnote-backref" href="#fnref:GUIDE_RAG" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>
        </article>
        <div class="col-3">
          <h4>Navigation</h4>
          <ol><li><a href="/wolfcon-2024-ai-workshop/intro-pre-conference/index.html">Introduction to WOLFcon AI Pre-conference Workshop</a></li><li><a href="/wolfcon-2024-ai-workshop/types-of-ai-ml-relevant-to-libraries/index.html">General Overview of AI and Machine Learning for Libraries</a></li><li><a href="/wolfcon-2024-ai-workshop/ethical-considerations-ai-ml-for-libraries/index.html">Ethical Considerations on using AI and Machine Learning for Libraries</a></li><li><a href="/wolfcon-2024-ai-workshop/exploring-llms/index.html">Exploring Large Language Models</a><ul><li><a href="chatgpt.html">OpenAI's ChatGPT</a></li><li><a href="claude.html">Anthropic's Claude</a></li><li><a href="gemini.html">Google Gemini</a></li><li><a href="local-llama.html">Meta's Llama</a></li><li><a href="generative-video.html">Generative Image and Video</a></li><li><a href="prompt-engineering.html">Prompt Engineering</a></li><li><strong>Retrieval Augmented Generation (RAG)</strong></li><li><a href="training-llms.html">Training Large Language Models (LLMs)</a></li></ul></li><li><a href="/wolfcon-2024-ai-workshop/folio-ai-use-cases/index.html">FOLIO AI Use Cases</a></li><li><a href="/wolfcon-2024-ai-workshop/next-steps-for-adopting-ai-and-ml-in-folio/index.html">Next Steps for Adopting AI and Machine Learning in FOLIO</a></li><li><a href="/wolfcon-2024-ai-workshop/recommended-resources-for-further-learning/index.html">Recommended Resources for Further Learning</a></li></ol>
        </div>
      </div>

    </div>
    <footer style="background-color: #0a3a85; color: white;" >
      <div class="container">Original Content by Jeremy Nelson &copy; 2024, <a href="https://github.com/jermnelson/wolfcon-02024-ai">Github</a></div>
    </footer> 
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
  </body>
</html>