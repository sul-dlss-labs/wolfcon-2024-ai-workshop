# Privacy 
With the wide-spread release of Large Language Models (LLMs) by various corporate and 
other organizations, the privacy of individuals may be compromised if their personal 
information is part of the massive amount of textual and other data used to train 
these models. Inclusion of personal information in the training data is problematic 
because the indviduals in question have not consented to have their data included and
even if the corporations have included counter-measures to keep personal data private,
there exist prompt engineering attacks that can reveal the raw training data from such 
models as ChatGPT.[^3]   


## Resources
1. [Generative AI's privacy problem](https://www.axios.com/2024/03/14/generative-ai-privacy-problem-chatgpt-openai)
2. [Privacy in Large Language Models: Attacks, Defenses and Future Directions](https://arxiv.org/abs/2310.10383)
[^3]: [Scalable Extraction of Training Data from (Production) Language Models](https://arxiv.org/abs/2311.17035)
