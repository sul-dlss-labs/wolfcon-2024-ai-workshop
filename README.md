# WOLFcon 2024 AI Preconference


## Prerequisites

### Required
Please completed the following items before the workshop:

- Email (or [signup](https://github.com/signup) first) your Github user name to jpnelson@stanford.edu
- After receiving your Github user name, you'll be added as a collaborator on the following repositories related to the course:
  - [edge-ai](https://github.com/folio-labs/edge-ai/)
  - [ai-workflows]()
- Ensure you can access at least two of the following LLM services (may require creating an account):
  - [ChatGPT](https://chatgpt.com/)
  - [Antropic Claude](https://www.anthropic.com/claude)
  - [Google Gemini](https://gemini.google.com/)
  - [Meta's Llama](https://llama.meta.com/")
- Go to the following [wiki page](https://github.com/folio-labs/ai-workflows/wiki) and select at 
  least two of the use-cases you are interested in exploring. Rank your choices. (If you would like to add 
  an AI use case that isn't listed, add a [new wiki page](https://github.com/folio-labs/ai-workflows/wiki/_new) 
  but be prepared for follow-up questions!)

### Optional
For those participants who are more technically inclined, the following items are optional but 
would allow for greater engagement and increase the utility of the workshop:

- Clone the edge-ai repository: `git clone https://github.com/folio-labs/edge-ai.git`
- Clone the ai-workflows repository: `git clone https://github.com/folio-labs/ai-workflows.git`
- Install [Docker Desktop](https://www.docker.com/products/docker-desktop/) with at least 10 GB 
  of memory to run [Airflow](https://airflow.apache.org/").
- Download and install [gpt4all](https://www.nomic.ai/gpt4all"); download a Llama-based model.


