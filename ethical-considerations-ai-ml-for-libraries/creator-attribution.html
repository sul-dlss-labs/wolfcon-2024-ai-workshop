<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AI Workflows for FOLIO - Creator Attribution and Copyright</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    
   
    <style>

    </style>
   
  </head>
  <body>
    <div class="header">
     <div class="container">
       <h1 style="color: #0a3a85; font-size: 3em;">WOLFcon 2024 - Understanding and Using AI Workflows with FOLIO</h1>
       <h3>23 September 2024</h3>
       <hr>
     </div>
    </div>
    <div class="container">
    
<div class="row">
  <article class="col-9">
    <h1>Creator Attribution and Copyright</h1>
<p>The training of Large Language Models (LLMs) requires massive amounts of text and other 
media that are commonly available on the open web. This content includes both copyrighted 
and public domain material, which can lead to generative text from these models closely 
resembling existing copyrighted works. </p>
<p>This resemblance in OpenAI's ChatGPT
outputs, led the New York Times and other publishers to file a 
lawsuit in December 2023 against OpenAI and Microsoft alleging copyright infringement.<sup id="fnref:NYTIMES_SUE"><a class="footnote-ref" href="#fn:NYTIMES_SUE">1</a></sup>  </p>
<p>OpenAI and Microsoft, in response to this lawsuit, claim that their use of copyright material
falls under the Fair Use doctrine in United States, a position reaffirmed by 
an Association of Research Libraries (ARL) blog post<sup id="fnref:ACRL_RESPONSE"><a class="footnote-ref" href="#fn:ACRL_RESPONSE">2</a></sup> which states in part:</p>
<blockquote>
<p>We drafted the principles on AI and copyright in response to efforts to amend copyright 
law to require licensing schemes for generative AI that could stunt the development of 
this technology, and undermine its utility to researchers, students, creators, and the public.
from <em>Training Generative AI Models on Copyrighted Works Is Fair Use</em><sup id="fnref2:ACRL_RESPONSE"><a class="footnote-ref" href="#fn:ACRL_RESPONSE">2</a></sup>.</p>
</blockquote>
<p>In their article, <em>Generative AI has a Visual Plagiarism Problem</em><sup id="fnref:GENAI_PLAGIARISM"><a class="footnote-ref" href="#fn:GENAI_PLAGIARISM">3</a></sup>, computer
scientists Gary Marcus and Reid Southern, demonstrate how image generation of such models as 
Midjourney and DALL-E 3 create "plagiaristic outputs" of black-box LLMs, while unpredictable,
allow for prompts that generate outputs remarkably similar to copyrighted images. They 
provide examples of querying both Midjourney and DALL-E to produce nearly identical outputs based 
on copyright material from Marvel movies and <em>The Simpsons</em> cartoons.</p>
<h2>Workshop Use-cases</h2>
<h3>Primary</h3>
<h3>Secondary</h3>
<h3>Tertiary</h3>
<div class="footnote">
<hr />
<ol>
<li id="fn:NYTIMES_SUE">
<p><a href="https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf">New York Times Legal Complaint December 2023</a>&#160;<a class="footnote-backref" href="#fnref:NYTIMES_SUE" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:ACRL_RESPONSE">
<p><a href="https://www.arl.org/blog/training-generative-ai-models-on-copyrighted-works-is-fair-use/">Training Generative AI Models on Copyrighted Works Is Fair Use</a>&#160;<a class="footnote-backref" href="#fnref:ACRL_RESPONSE" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:ACRL_RESPONSE" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:GENAI_PLAGIARISM">
<p><a href="https://spectrum.ieee.org/midjourney-copyright">Generative AI Has a Visual Plagiarism Problem Experiments with Midjourney and DALL-E 3 show a copyright minefield</a>&#160;<a class="footnote-backref" href="#fnref:GENAI_PLAGIARISM" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </article>
  <div class="col-3">
    <h4>Navigation</h4>
     <ol><li><a href="/wolfcon-2024-ai-workshop/intro-pre-conference/index.html">Introduction to WOLFcon AI Pre-conference Workshop</a></li><li><a href="/wolfcon-2024-ai-workshop/types-of-ai-ml-relevant-to-libraries/index.html">General Overview of AI and Machine Learning for Libraries</a></li><li><a href="/wolfcon-2024-ai-workshop/ethical-considerations-ai-ml-for-libraries/index.html">Ethical Considerations on using AI and Machine Learning for Libraries</a><ul><li><a href="bias.html">Bias and AI</a></li><li><a href="academic-fraud.html">Academic Fraud - Plagiarism and Acceptable Use</a></li><li><strong>Creator Attribution and Copyright</strong></li><li><a href="privacy.html">Privacy Concerns in Large Language Models</a></li><li><a href="guidelines.html">Guidelines for Incorporating AI</a></li><li><a href="carbon-footprint.html">Carbon Footprint of LLMs</a></li><li><a href="deepfakes.html">Deepfakes</a></li><li><a href="ai-slop.html">AI Slop</a></li><li><a href="hallucinations-llms.html">Hallucinations and Generative AI</a></li><li><a href="p-doom-agi.html">p(doom) and Artificial General Intelligence (AGI)</a></li></ul></li><li><a href="/wolfcon-2024-ai-workshop/exploring-llms/index.html">Exploring Large Language Models</a></li><li><a href="/wolfcon-2024-ai-workshop/folio-ai-use-cases/index.html">FOLIO AI Use Cases</a></li><li><a href="/wolfcon-2024-ai-workshop/next-steps-for-adopting-ai-and-ml-in-folio/index.html">Next Steps for Adopting AI and Machine Learning in FOLIO</a></li><li><a href="/wolfcon-2024-ai-workshop/recommended-resources-for-further-learning/index.html">Recommended Resources for Further Learning</a></li></ol>
  </div>
</div>

    </div>
    <footer style="background-color: #0a3a85; color: white;" >
      <div class="container">Original Content by Jeremy Nelson &copy; 2024, <a href="https://github.com/sul-dlss-labs/wolfcon-02024-ai">Github</a></div>
    </footer> 
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    
  </body>
</html>