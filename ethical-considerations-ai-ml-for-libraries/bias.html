<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AI Workflows for FOLIO - Bias and AI</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
    
   
    <style>

    </style>
   
  </head>
  <body>
    <div class="header">
     <div class="container">
       <h1 style="color: #0a3a85; font-size: 3em;">WOLFcon 2024 - Understanding and Using AI Workflows with FOLIO</h1>
       <h3>23 September 2024</h3>
       <hr>
     </div>
    </div>
    <div class="container">
    
<div class="row">
  <article class="col-9">
    <h1>Bias and AI</h1>
<figure>
  <blockquote class="blockquote">
   <p>
   AI bias, also referred to as machine learning bias or algorithm bias, refers 
   to AI systems that produce biased results that reflect and perpetuate human 
   biases within a society, including historical and current social inequality. 
   Bias can be found in the initial training data, the algorithm, or the 
   predictions the algorithm produces.
   </p>
  </blockquote>
  <figcaption class="blockquote-footer" markdown="span">
   IBM<sup><a class="footnote-ref" href="#fn:IBM_AI_BIAS">3</a></sup>
  </figcaption>
</figure>

<h2>Sources of Bias</h2>
<h3>Training data</h3>
<ul>
<li>
<p>Training data can over or under sample underrepresented groups</p>
<ul>
<li><strong>Example</strong>:
  Exclusively using copyright-free material from the 1930s and earlier 
  may under-represent many groups.</li>
</ul>
</li>
<li>
<p>Training data can also be bias in labeling by excluding or over-representing
  certain categories or characteristics.</p>
<ul>
<li><strong>Example</strong>
  If using a controlled vocabulary that focuses on Western categories and concepts,
  might miss valid valid indigenous concepts and constructions that may be present in the
  training data.  </li>
</ul>
</li>
</ul>
<h3>Algorithms</h3>
<ul>
<li>
<p>Algorithms based on biased data could perpetrate underlying flaws</p>
<ul>
<li><strong>Example</strong>
  If training data is taken to be relatively free of bias but bias exist, 
  algorithms at risk of Type II error of erroneous acceptance. </li>
</ul>
</li>
<li>
<p>Programmers could introduce personal bias intentionally or unintentionally</p>
</li>
<li>
<p>Unintended consequences of using proxies for characteristics in the 
  population</p>
<ul>
<li><strong>Example</strong>
  Using geographic location as a proxy for income may skew analysis </li>
</ul>
</li>
</ul>
<h3>Cognitive</h3>
<ul>
<li>People's experiences and preferences can introduce and favor bias or 
  weighting of outcomes or selection of data.</li>
</ul>
<h2>Mitigation and Responses</h2>
<p>How can we mitigate or respond to AI and Machine Learning bias? </p>
<p>See how the LLM vendors respond and attempt to mitigate bias in their models:</p>
<ul>
<li>
<p><strong>OpenAI</strong> Description of using Fine-tuning to addressing bias<sup id="fnref:HOW_AI_BEHAVE"><a class="footnote-ref" href="#fn:HOW_AI_BEHAVE">2</a></sup></p>
</li>
<li>
<p><strong>Anthropic</strong> Evaluating and Mitigating Discrimination in Language Model Decisions<sup id="fnref:CLAUDE_LANG"><a class="footnote-ref" href="#fn:CLAUDE_LANG">3</a></sup></p>
</li>
<li>
<p><strong>Google</strong> Gemini for Google Cloud and responsible AI<sup id="fnref:GEMINI"><a class="footnote-ref" href="#fn:GEMINI">4</a></sup></p>
</li>
</ul>
<h2>Resources</h2>
<ul>
<li>https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights</li>
<li>https://lin-web.clarkson.edu/~jmatthew/publications/ManagingBiasInAI_CAMERAREADY.pdf </li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:IBM_AI_BIAS">
<p><a href="https://www.ibm.com/blog/shedding-light-on-ai-bias-with-real-world-examples/">Shedding light on AI bias with real world examples</a>&#160;<a class="footnote-backref" href="#fnref:IBM_AI_BIAS" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:HOW_AI_BEHAVE">
<p><a href="https://openai.com/index/how-should-ai-systems-behave/">How should AI systems behave, and who should decide?</a>&#160;<a class="footnote-backref" href="#fnref:HOW_AI_BEHAVE" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:CLAUDE_LANG">
<p><a href="https://www.anthropic.com/news/evaluating-and-mitigating-discrimination-in-language-model-decisions">Evaluating and Mitigating Discrimination in Language Model Decisions</a>&#160;<a class="footnote-backref" href="#fnref:CLAUDE_LANG" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:GEMINI">
<p><a href="https://cloud.google.com/gemini/docs/discover/responsible-ai">Gemini for Google Cloud and responsible AI</a>&#160;<a class="footnote-backref" href="#fnref:GEMINI" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </article>
  <div class="col-3">
    <h4>Navigation</h4>
     <ol><li><a href="/wolfcon-2024-ai-workshop/intro-pre-conference/index.html">Introduction to WOLFcon AI Pre-conference Workshop</a></li><li><a href="/wolfcon-2024-ai-workshop/types-of-ai-ml-relevant-to-libraries/index.html">General Overview of AI and Machine Learning for Libraries</a></li><li><a href="/wolfcon-2024-ai-workshop/exploring-llms/index.html">Exploring Large Language Models</a></li><li><a href="/wolfcon-2024-ai-workshop/ethical-considerations-ai-ml-for-libraries/index.html">Ethical Considerations on using AI and Machine Learning for Libraries</a><ul><li><strong>Bias and AI</strong></li><li><a href="academic-fraud.html">Academic Fraud and Artificial Intelligence</a></li><li><a href="creator-attribution.html">Creator Attribution and Copyright</a></li><li><a href="privacy.html">Privacy Concerns in Large Language Models</a></li><li><a href="guidelines.html">Guidelines for Incorporating AI</a></li><li><a href="carbon-footprint.html">Carbon Footprint of LLMs</a></li><li><a href="deepfakes.html">Deepfakes</a></li><li><a href="ai-slop.html">AI Slop</a></li><li><a href="hallucinations-llms.html">Hallucinations and Generative AI</a></li><li><a href="p-doom-agi.html">p(doom) and Artificial General Intelligence (AGI)</a></li></ul></li><li><a href="/wolfcon-2024-ai-workshop/folio-ai-use-cases/index.html">FOLIO AI Use Cases</a></li><li><a href="/wolfcon-2024-ai-workshop/next-steps-for-adopting-ai-and-ml-in-folio/index.html">Next Steps for Adopting AI and Machine Learning in FOLIO</a></li><li><a href="/wolfcon-2024-ai-workshop/recommended-resources-for-further-learning/index.html">Recommended Resources for Further Learning</a></li></ol>
  </div>
</div>

    </div>
    <footer style="background-color: #0a3a85; color: white;" >
      <div class="container">Original Content by Jeremy Nelson &copy; 2024, <a href="https://github.com/sul-dlss-labs/wolfcon-2024-ai-workshop/">Github</a></div>
    </footer> 
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    
  </body>
</html>