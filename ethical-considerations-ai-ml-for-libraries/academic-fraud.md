# Academic Fraud and Artificial Intelligence 

## Plagiarism 
One of the immediate concerns regarding academic fraud is the use of 
Large Language Models (LLMs) that generate convincing and coherent text that
students and researchers can pass off as original work. The growth and inclusion 
of generative text into academic articles has been widespread, particularly in 
the computer science literature[^HAI_LLM] with estimates ranging as high as 17%[^ARXIV_01]. 

Examples are widely shared in social media[^X_ELSIVER] and are becoming increasingly common.


## What is acceptable use?
Many journals like Nature[^NATURE], Science[^SCIENCE], Elsevier[^ELSEVIER], and IEEE [^IEEE]
have similar requirements for using 
Generative AI in academic articles.
They all allow the use of LLMs for copy-editing tasks like grammar checking. Another commonality in these
guidelines is the disclosure of using of LLMs or other AI, with some journals requiring the specific
AI system to be included in the article.

> Just as a reminder; LLMs have been used for copy-editing purpose for 
> the content of this workshop!

Some of the journals prohibit the listing or attributing authorship of an article by a 
LLM model[^NATURE][^SCIENCE].

A general recommendation is to be overly cautious and disclose any use of Generative AI in the creation
of academic work unless prohibited by the journal.

## Use of LLMs in Education
In this blob post[^CRAFT], Alice Evans provides the following guidance for educators:

- Cultivating AI Literacy by designing classroom activities that use LLMs like Claude
  to help answer and explain questions on the class material. 
- Design Assessments that exceed current AI functionality by assuming that students will
  use AI but that require students to have a deeper understanding of the source material
  and use deadlines to limit the time a student has to complete the assessment.

A further note of caution from a recent paper[^GENAI] about a study that demonstrated that
allowing students to use GPT 4.0 in their course improved their performance but when GPT 
is no longer available, the student perform worse than students who have never used a LLM. 

## Resources
- [Artificial intelligence and academic integrity: striking a balance](https://www.timeshighereducation.com/campus/artificial-intelligence-and-academic-integrity-striking-balance)


[^HAI_LLM]: [How Much Research Is Being Written by Large Language Models?](https://hai.stanford.edu/news/how-much-research-being-written-large-language-models)
[^ARXIV_01]: [Mapping the Increasing Use of LLMs in Scientific Papers](https://arxiv.org/abs/2404.01268)
[^X_ELSIVER]: [X Post on use of LLMs in an Elsevier article](https://x.com/gcabanac/status/1767574447337124290?s=20)
[^NATURE]: [Artificial Intelligence (AI)](https://www.nature.com/nature-portfolio/editorial-policies/ai)
[^ELSEVIER]: [The use of generative AI and AI-assisted technologies in writing for Elsevier](https://www.elsevier.com/about/policies-and-standards/the-use-of-generative-ai-and-ai-assisted-technologies-in-writing-for-elsevier)
[^SCIENCE]: [Science Journals Editorial Policies](https://www.science.org/content/page/science-journals-editorial-policies)
[^IEEE]: [Guidelines for Artificial Intelligence (AI)-Generated Text](https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/submission-and-peer-review-policies/#ai-generated-text)
[^CRAFT]: [Crafting AI-Complementary Skills and Bulletproof Assessments](https://www.ggd.world/p/crafting-ai-complementary-skills)
[^GENAI]: [Generative AI Can Harm Learning](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895486)

