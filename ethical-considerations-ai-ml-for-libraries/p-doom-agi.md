# p(doom) and Artificial General Intelligence (AGI)
What is the probability of AI taking over or even the complete destruction of 
civilization? This question has become a popular topic with the growth of generative
AI in the past couple of years[^FAST]. Known as p(doom), or the probability of an AI
apocalypse, is on a scale from 1 to 100 that AI will develop into a malignant 
superintelligence. While p(doom) is a sensationalist metric, the disturbing reality 
that many of the top AI scientists, engineers, and executives all have p(doom) 
estimates that are surprising high[^PAUSEAI] with the mean estimate from AI engineers
of a 40% p(doom) score[^ENGINEERS_SURVEY]. 

## Exercise
Please go to this [survey](https://docs.google.com/forms/d/e/1FAIpQLSd3-b7wS3ZOqDtpHVbO3p8PqfsZQKuuZEjgJXp6wCRzpCdHlA/viewform?usp=sf_link) to submit your p(doom) number.


## Artificial General Intelligence (AGI)
Artificial General Intelligence (AGI)[^AGI] is the concept of an AI that surpasses human intelligence 
across a wide range cognitive tasks. Related to this idea of AGI is the fear that once AI reaches
this threshold, AI will bootstrap itself to greater intelligence in a rapid fashion and become an 
intelligence that is beyond anything we can conceptualize. 

## AI Alignment
In a 2003 paper[^BOSTROM], Nick Bostrom provided an example of a superintelligent AI that has an 
initial motivation to maximize the manufacturing of paperclips could eventually ignore any human
goals and turn the entire planet into manufacturing paperclips to the detriment of all life on Earth.

Minimizing p(doom) through aligning AGI's goals with our own goals and values is an active area
of research in both academic and by AI companies.
 
## Footnotes
[^FAST]: [P(doom) is AI’s latest apocalypse metric. Here’s how to calculate your score](https://www.fastcompany.com/90994526/pdoom-explained-how-to-calculate-your-score-on-ai-apocalypse-metric)
[^PAUSEAI]: [List of p(doom) values](https://pauseai.info/pdoom)
[^ENGINEERS_SURVEY]: [State of AI Engineering 2023](https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631)
[^AGI]: [Artificial General Intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)
[^BOSTROM]: [Ethical Issues in Advanced Artificial Intelligence](https://nickbostrom.com/ethics/ai)

[^BENEFIT_RISK]: [Benefits & Risks of Artificial Intelligence](https://futureoflife.org/ai/benefits-risks-of-artificial-intelligence/)

